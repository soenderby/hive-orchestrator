{"id":"hive-0pp","title":"Fix status.py display values","description":"Update status.py to use 'closed' instead of 'done':\n- Line 57: Change task_counts dict key\n- Line 115: Change display label\n- Lines 124-125: Update variable references","status":"closed","priority":0,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:40:11.172574362+01:00","created_by":"jsk","updated_at":"2026-02-03T12:54:33.144279147+01:00","closed_at":"2026-02-03T12:54:33.144279147+01:00","close_reason":"Closed"}
{"id":"hive-0ui","title":"Implement hive status with multiple workers","description":"Show all active workers, their current tasks, worktrees, and progress. Display blocked tasks and what's blocking them. Show overall task counts (done/active/blocked).","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:08:54.163850072+01:00","created_by":"jsk","updated_at":"2026-02-03T09:00:11.551836637+01:00","closed_at":"2026-02-03T09:00:11.551836637+01:00","close_reason":"Already implemented in Phase 3. hive status command shows active workers, current tasks, task statistics, and overall progress. Supports --json flag for scripting.","dependencies":[{"issue_id":"hive-0ui","depends_on_id":"hive-9qe","type":"blocks","created_at":"2026-02-02T08:11:29.258777611+01:00","created_by":"jsk"}]}
{"id":"hive-0uy","title":"Implement hive merge workflow","description":"hive merge \u003cworker\u003e command for manual merge resolution. Handle conflicts: preserve worktree, human resolves, then hive cleanup. Support hive sync for push/pull all branches.","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:09:15.646197998+01:00","created_by":"jsk","updated_at":"2026-02-03T09:14:01.708109478+01:00","closed_at":"2026-02-03T09:14:01.708109478+01:00","close_reason":"Closed"}
{"id":"hive-130","title":"Epic: Make Main Branch Configurable","description":"Make the default branch configurable instead of hardcoding 'main'. Support projects using 'master' or other branch names.","status":"open","priority":2,"issue_type":"epic","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:39:50.353778506+01:00","created_by":"jsk","updated_at":"2026-02-03T12:39:50.353778506+01:00","dependencies":[{"issue_id":"hive-130","depends_on_id":"hive-4k9","type":"blocks","created_at":"2026-02-03T12:45:30.377158477+01:00","created_by":"jsk"},{"issue_id":"hive-130","depends_on_id":"hive-vsq","type":"blocks","created_at":"2026-02-03T12:49:03.416761041+01:00","created_by":"jsk"},{"issue_id":"hive-130","depends_on_id":"hive-5of","type":"blocks","created_at":"2026-02-03T12:49:11.074111532+01:00","created_by":"jsk"}]}
{"id":"hive-225","title":"Implement minimal daemon (hived)","description":"Background daemon: poll for stuck workers (no activity for stuck_threshold), report status when queried, optional desktop notifications on failure. Commands: hived start/stop/status.","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:09:07.697818901+01:00","created_by":"jsk","updated_at":"2026-02-03T09:22:46.719564387+01:00","closed_at":"2026-02-03T09:22:46.719564387+01:00","close_reason":"Closed"}
{"id":"hive-318","title":"Phase 2: Beads Integration - Full task lifecycle","description":"Full Beads integration: task commands, atomic claims, dependency tracking, too-big workflow, and discovered work support.","status":"closed","priority":1,"issue_type":"feature","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:05:42.027662614+01:00","created_by":"jsk","updated_at":"2026-02-03T07:48:39.385021975+01:00","closed_at":"2026-02-03T07:48:39.385021975+01:00","close_reason":"Phase 2 is fully implemented with all tests passing (70/70). Includes: hive task commands (list, show, add, too-big), atomic claim semantics (bd update --claim), dependency tracking integration, too-big workflow with decomposition guidance, and discovered work support (--discovered-from flag).","dependencies":[{"issue_id":"hive-318","depends_on_id":"hive-nu6","type":"blocks","created_at":"2026-02-02T08:06:17.861591282+01:00","created_by":"jsk"}]}
{"id":"hive-3ep","title":"Update documentation for correct status values","description":"Update README.md and hive-plan.md to document correct Beads status values:\n- open (not planned)\n- in_progress\n- closed (not done)\n- blocked, too_big, failed","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:40:26.775076877+01:00","created_by":"jsk","updated_at":"2026-02-03T12:59:15.003960872+01:00","closed_at":"2026-02-03T12:59:15.003960872+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-3ep","depends_on_id":"hive-7rz","type":"blocks","created_at":"2026-02-03T12:43:53.345562417+01:00","created_by":"jsk"},{"issue_id":"hive-3ep","depends_on_id":"hive-0pp","type":"blocks","created_at":"2026-02-03T12:44:00.642125845+01:00","created_by":"jsk"},{"issue_id":"hive-3ep","depends_on_id":"hive-a13","type":"blocks","created_at":"2026-02-03T12:44:07.839384121+01:00","created_by":"jsk"}]}
{"id":"hive-48k","title":"Implement CLAUDE.md context generation","description":"Generate per-task CLAUDE.md with: task ID, title, description, acceptance criteria, worker instructions (how to signal done/too_big/blocked), and project context from .hive/plan.md.","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:07:13.698037867+01:00","created_by":"jsk","updated_at":"2026-02-02T08:46:19.673013593+01:00","closed_at":"2026-02-02T08:46:19.673013593+01:00","close_reason":"Closed"}
{"id":"hive-4cn","title":"Update README.md: replace hive task with bd commands","description":"Replace all 'hive task' references with equivalent bd commands. Remove the 'hive task' command section.","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T09:41:49.561993385+01:00","created_by":"jsk","updated_at":"2026-02-03T12:16:40.542802292+01:00","closed_at":"2026-02-03T12:16:40.542802292+01:00","close_reason":"Updated README.md - replaced all hive task references with bd commands. Tests pass.","dependencies":[{"issue_id":"hive-4cn","depends_on_id":"hive-dlr","type":"blocks","created_at":"2026-02-03T09:42:34.714358545+01:00","created_by":"jsk"}]}
{"id":"hive-4k9","title":"Epic: Implement Config Loading","description":"Create config loading module. Currently config.toml is created by hive init but never loaded - all values are hardcoded.","status":"closed","priority":2,"issue_type":"epic","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:39:42.6979489+01:00","created_by":"jsk","updated_at":"2026-02-03T13:15:44.005984299+01:00","closed_at":"2026-02-03T13:15:44.005984299+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-4k9","depends_on_id":"hive-ia1","type":"blocks","created_at":"2026-02-03T12:48:40.291159107+01:00","created_by":"jsk"},{"issue_id":"hive-4k9","depends_on_id":"hive-vb6","type":"blocks","created_at":"2026-02-03T12:48:48.179046326+01:00","created_by":"jsk"},{"issue_id":"hive-4k9","depends_on_id":"hive-qem","type":"blocks","created_at":"2026-02-03T12:48:55.597654842+01:00","created_by":"jsk"}]}
{"id":"hive-55e","title":"Remove hive task command wrappers","description":"Remove the thin bd wrappers (hive task list/show/add/too-big) per review findings. Users should use bd commands directly.","status":"closed","priority":2,"issue_type":"epic","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T09:41:27.375265053+01:00","created_by":"jsk","updated_at":"2026-02-03T09:45:59.818319406+01:00","closed_at":"2026-02-03T09:45:59.818319406+01:00","close_reason":"Planning complete. Subtasks defined and ready for implementation."}
{"id":"hive-5i2","title":"Implement conflict detection (module-based)","description":"Track module field in Beads tasks. Warn during planning if parallel tasks touch same module. Add --parallel-safe flag to tasks. Mark conflicting tasks with blocked-by.","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:08:38.074963077+01:00","created_by":"jsk","updated_at":"2026-02-03T08:41:59.078419991+01:00","closed_at":"2026-02-03T08:41:59.078419991+01:00","close_reason":"Already implemented in Phase 3. hive work --parallel N is complete with multiprocessing support, atomic claims handle worker coordination, and module-based conflict detection is covered by atomic claims + dependency tracking."}
{"id":"hive-5of","title":"Update hardcoded 'main' branch references","description":"Replace hardcoded 'main' with config value in:\n- work.py: lines 173, 316\n- merge.py: line 234\n- worktree.py: line 31 default parameter","status":"open","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:41:42.516097737+01:00","created_by":"jsk","updated_at":"2026-02-03T12:41:42.516097737+01:00","dependencies":[{"issue_id":"hive-5of","depends_on_id":"hive-vsq","type":"blocks","created_at":"2026-02-03T12:44:45.147916705+01:00","created_by":"jsk"}]}
{"id":"hive-608","title":"Phase 3: Parallel Execution - Safe multi-worker support","description":"Parallel execution support: multiple workers, conflict detection, worker coordination, and multi-worker status.","status":"closed","priority":2,"issue_type":"feature","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:05:50.379124233+01:00","created_by":"jsk","updated_at":"2026-02-03T07:56:17.059213285+01:00","closed_at":"2026-02-03T07:56:17.059213285+01:00","close_reason":"Phase 3 fully implemented with all tests passing (80/80). Includes: hive work --parallel N (multiprocessing support), worker registry management (register/unregister/update), hive status command with worker and task statistics, and comprehensive test coverage for all new features.","dependencies":[{"issue_id":"hive-608","depends_on_id":"hive-318","type":"blocks","created_at":"2026-02-02T08:06:25.548826303+01:00","created_by":"jsk"}]}
{"id":"hive-64d","title":"Implement discovered work support","description":"Agent can run bd create 'description' --discovered-from \u003ctask_id\u003e to file work found during execution. Links back to parent task. Creates new planned tasks without blocking current work.","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:08:15.851378261+01:00","created_by":"jsk","updated_at":"2026-02-02T14:06:36.809878793+01:00","closed_at":"2026-02-02T14:06:36.809878793+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-64d","depends_on_id":"hive-djm","type":"blocks","created_at":"2026-02-02T08:11:04.491276861+01:00","created_by":"jsk"}]}
{"id":"hive-6e3","title":"Implement error handling and recovery","description":"Handle all failure modes: spawn failures, timeouts, crashes, merge conflicts. Preserve worktrees for inspection when needed. Clear error messages with actionable notes in Beads.","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:09:23.553734844+01:00","created_by":"jsk","updated_at":"2026-02-03T09:07:03.355374365+01:00","closed_at":"2026-02-03T09:07:03.355374365+01:00","close_reason":"Enhanced error handling with actionable recovery hints. Added fail_task_with_recovery() function for structured error reporting. Improved error messages for: worktree creation, context generation, spawn failures, timeouts, crashes, merge conflicts, and tmux command failures. Added prerequisite check for tmux. All error paths now include recovery suggestions. Tests updated and passing (80/80)."}
{"id":"hive-72d","title":"Epic: Add File Locking to Worker Registry","description":"Add file locking to workers.json to prevent race conditions when multiple parallel workers access it simultaneously.","status":"closed","priority":1,"issue_type":"epic","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:39:35.231452461+01:00","created_by":"jsk","updated_at":"2026-02-03T13:09:17.375952736+01:00","closed_at":"2026-02-03T13:09:17.375952736+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-72d","depends_on_id":"hive-9jj","type":"blocks","created_at":"2026-02-03T12:48:17.466576652+01:00","created_by":"jsk"},{"issue_id":"hive-72d","depends_on_id":"hive-uxl","type":"blocks","created_at":"2026-02-03T12:48:25.119034439+01:00","created_by":"jsk"},{"issue_id":"hive-72d","depends_on_id":"hive-bbk","type":"blocks","created_at":"2026-02-03T12:48:32.598609306+01:00","created_by":"jsk"}]}
{"id":"hive-7rz","title":"Fix work.py status value checks","description":"Change status checks in work.py:\n- Line 494: Change 'done' to 'closed'\n- Verify other status checks match Beads (too_big, blocked, failed)","status":"closed","priority":0,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:40:03.355043165+01:00","created_by":"jsk","updated_at":"2026-02-03T12:53:34.815249138+01:00","closed_at":"2026-02-03T12:53:34.815249138+01:00","close_reason":"Closed"}
{"id":"hive-9jj","title":"Create hive/utils.py with file locking utilities","description":"Create new utils.py module with:\n- locked_json_file() context manager using fcntl.flock()\n- Atomic write pattern (temp file + rename)\n- Cross-platform fallback for non-Unix systems","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:40:39.846403795+01:00","created_by":"jsk","updated_at":"2026-02-03T13:04:29.820643535+01:00","closed_at":"2026-02-03T13:04:29.820643535+01:00","close_reason":"Closed"}
{"id":"hive-9qe","title":"Implement hive work --parallel N","description":"Spawn N independent ralph loops, each picking unassigned/unblocked tasks. Uses atomic claims to prevent double-assignment. Hard limit from config max_workers.","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:08:29.242342444+01:00","created_by":"jsk","updated_at":"2026-02-03T08:41:59.025211391+01:00","closed_at":"2026-02-03T08:41:59.025211391+01:00","close_reason":"Already implemented in Phase 3. hive work --parallel N is complete with multiprocessing support, atomic claims handle worker coordination, and module-based conflict detection is covered by atomic claims + dependency tracking.","dependencies":[{"issue_id":"hive-9qe","depends_on_id":"hive-gu5","type":"blocks","created_at":"2026-02-02T08:11:12.935167256+01:00","created_by":"jsk"}]}
{"id":"hive-a13","title":"Fix CLAUDE.md template status instructions","description":"Fix context.py CLAUDE.md template to give correct instructions:\n- Line 84: Change --status=blocked to --status=too_big for too-big tasks\n- Line 113: Change --status=blocked to --status=failed for failed tasks","status":"closed","priority":0,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:40:18.996346845+01:00","created_by":"jsk","updated_at":"2026-02-03T12:55:29.867934477+01:00","closed_at":"2026-02-03T12:55:29.867934477+01:00","close_reason":"Closed"}
{"id":"hive-bbk","title":"Update status.py and daemon.py to use file locking","description":"Update worker registry reads in:\n- status.py (lines 24-37)\n- daemon.py (lines 71-82)\nto use locked_json_file() for consistent reads","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:40:55.5767829+01:00","created_by":"jsk","updated_at":"2026-02-03T13:06:39.835667244+01:00","closed_at":"2026-02-03T13:06:39.835667244+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-bbk","depends_on_id":"hive-9jj","type":"blocks","created_at":"2026-02-03T12:44:23.061074769+01:00","created_by":"jsk"}]}
{"id":"hive-bke","title":"Update hive-plan.md: replace hive task with bd commands","description":"Replace all 'hive task' references with equivalent bd commands in the architecture document.","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T09:41:57.541272846+01:00","created_by":"jsk","updated_at":"2026-02-03T12:18:17.898580088+01:00","closed_at":"2026-02-03T12:18:17.898580088+01:00","close_reason":"Updated hive-plan.md - replaced all hive task references with bd commands. Tests pass.","dependencies":[{"issue_id":"hive-bke","depends_on_id":"hive-dlr","type":"blocks","created_at":"2026-02-03T09:42:42.208746671+01:00","created_by":"jsk"}]}
{"id":"hive-c2v","title":"Implement worktree create/cleanup","description":"Create unique worktrees: worktrees/\u003cworker-id\u003e-\u003ctask-id\u003e/ with branch task-\u003ctask-id\u003e from main. Cleanup: git worktree remove, git branch -D. Handle stale worktrees from crashes.","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:07:21.425456064+01:00","created_by":"jsk","updated_at":"2026-02-02T08:50:41.815294688+01:00","closed_at":"2026-02-02T08:50:41.815294688+01:00","close_reason":"Closed"}
{"id":"hive-djm","title":"Implement hive work command (serial)","description":"Run the Ralph loop for single worker: claim task from Beads, create worktree, generate CLAUDE.md, spawn agent in tmux, poll for completion, handle outcomes (done/too_big/blocked/failed), merge if done, cleanup.","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:07:04.462230688+01:00","created_by":"jsk","updated_at":"2026-02-02T09:11:06.065331564+01:00","closed_at":"2026-02-02T09:11:06.065331564+01:00","close_reason":"Implemented hive work command with serial Ralph loop execution, including task claiming, worktree management, agent spawning in tmux, and completion polling with comprehensive tests","dependencies":[{"issue_id":"hive-djm","depends_on_id":"hive-krb","type":"blocks","created_at":"2026-02-02T08:10:00.481332977+01:00","created_by":"jsk"},{"issue_id":"hive-djm","depends_on_id":"hive-48k","type":"blocks","created_at":"2026-02-02T08:10:08.511972205+01:00","created_by":"jsk"},{"issue_id":"hive-djm","depends_on_id":"hive-c2v","type":"blocks","created_at":"2026-02-02T08:10:16.517442448+01:00","created_by":"jsk"}]}
{"id":"hive-dlr","title":"Remove task.py and test_task.py","description":"Delete hive/commands/task.py and tests/test_task.py. Remove task_cmd import from cli.py.","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T09:41:41.632876618+01:00","created_by":"jsk","updated_at":"2026-02-03T09:49:25.910714153+01:00","closed_at":"2026-02-03T09:49:25.910714153+01:00","close_reason":"Removed task.py, test_task.py, and CLI registration. All 102 tests pass.","dependencies":[{"issue_id":"hive-dlr","depends_on_id":"hive-55e","type":"blocks","created_at":"2026-02-03T09:42:27.046435866+01:00","created_by":"jsk"}]}
{"id":"hive-e7d","title":"Add tests for config and utils modules","description":"Create new test files:\n- tests/test_config.py: config loading, defaults, branch detection\n- tests/test_utils.py: file locking behavior","status":"open","priority":3,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:41:49.95044424+01:00","created_by":"jsk","updated_at":"2026-02-03T12:41:49.95044424+01:00","dependencies":[{"issue_id":"hive-e7d","depends_on_id":"hive-ia1","type":"blocks","created_at":"2026-02-03T12:44:53.091526315+01:00","created_by":"jsk"},{"issue_id":"hive-e7d","depends_on_id":"hive-9jj","type":"blocks","created_at":"2026-02-03T12:45:00.458861844+01:00","created_by":"jsk"}]}
{"id":"hive-fd7","title":"Implement dependency tracking integration","description":"Wire up Beads blocked-by relationships: bd ready only returns tasks with all dependencies done AND merged. Update task selection logic to respect dependencies.","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:08:00.017131074+01:00","created_by":"jsk","updated_at":"2026-02-02T09:42:46.528338895+01:00","closed_at":"2026-02-02T09:42:46.528338895+01:00","close_reason":"Implemented dependency tracking - tasks with open/in_progress dependencies are now skipped","dependencies":[{"issue_id":"hive-fd7","depends_on_id":"hive-djm","type":"blocks","created_at":"2026-02-02T08:10:49.184504977+01:00","created_by":"jsk"}]}
{"id":"hive-fpb","title":"Implement worker coordination via atomic claims","description":"Multiple workers race for tasks: if bd update fails (task already in_progress), worker retries with next task. No lock files, just Beads state as coordination layer.","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:08:45.927164389+01:00","created_by":"jsk","updated_at":"2026-02-03T08:41:59.122863124+01:00","closed_at":"2026-02-03T08:41:59.122863124+01:00","close_reason":"Already implemented in Phase 3. hive work --parallel N is complete with multiprocessing support, atomic claims handle worker coordination, and module-based conflict detection is covered by atomic claims + dependency tracking.","dependencies":[{"issue_id":"hive-fpb","depends_on_id":"hive-gu5","type":"blocks","created_at":"2026-02-02T08:11:21.163167372+01:00","created_by":"jsk"}]}
{"id":"hive-gu5","title":"Implement atomic claim semantics","description":"Ensure task can only transition planned→in_progress exactly once. Either bd update fails if not planned, or implement bd claim \u003ctask_id\u003e --worker \u003cid\u003e with compare-and-swap. Critical for parallel correctness.","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:07:51.737046502+01:00","created_by":"jsk","updated_at":"2026-02-02T09:31:39.000094697+01:00","closed_at":"2026-02-02T09:31:39.000094697+01:00","close_reason":"Implemented atomic claim semantics using bd update --claim flag","dependencies":[{"issue_id":"hive-gu5","depends_on_id":"hive-djm","type":"blocks","created_at":"2026-02-02T08:10:41.544489286+01:00","created_by":"jsk"}]}
{"id":"hive-ia1","title":"Create hive/config.py module","description":"Create config loading module with:\n- HiveConfig dataclass with all configuration fields\n- load_config() function to read .hive/config.toml\n- Default values for all fields\n- New fields: default_branch, poll_interval, task_timeout","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:41:07.94406702+01:00","created_by":"jsk","updated_at":"2026-02-03T13:11:35.524231311+01:00","closed_at":"2026-02-03T13:11:35.524231311+01:00","close_reason":"Closed"}
{"id":"hive-iqe","title":"Implement hive task commands","description":"Thin wrappers around bd: hive task list (bd list), hive task show \u003cid\u003e (bd show), hive task add 'description' (bd create for discovered work).","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:07:43.449453136+01:00","created_by":"jsk","updated_at":"2026-02-02T09:23:02.524345343+01:00","closed_at":"2026-02-02T09:23:02.524345343+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-iqe","depends_on_id":"hive-djm","type":"blocks","created_at":"2026-02-02T08:10:33.084108568+01:00","created_by":"jsk"}]}
{"id":"hive-krb","title":"Implement hive init command","description":"Setup .hive/ directory structure with config.toml, workers.json, and plan.md. Verify beads is initialized. Create worktrees/ directory.","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:06:47.364017081+01:00","created_by":"jsk","updated_at":"2026-02-02T08:32:49.753101222+01:00","closed_at":"2026-02-02T08:32:49.753101222+01:00","close_reason":"Closed"}
{"id":"hive-l1w","title":"Review: Evaluate task command wrapper vs direct Beads usage","description":"Review whether the hive task command wrappers (hive task list/show/add) add sufficient value, or if users should use Beads (bd) commands directly.\n\n## Questions to consider:\n1. Does wrapping bd commands in hive task add meaningful value?\n2. Is the abstraction worth the maintenance overhead?\n3. Would users benefit from learning bd directly instead?\n4. Are there hive-specific enhancements we could add to justify the wrapper?\n5. Does it create confusion having two ways to do the same thing?\n\n## Current implementation:\n- hive task list → bd list\n- hive task show \u003cid\u003e → bd show \u003cid\u003e\n- hive task add 'desc' → bd create (with discovered work note)\n\n## Possible outcomes:\n- Keep as-is: Wrappers provide value through consistent hive CLI\n- Remove wrappers: Users should use bd directly\n- Enhance wrappers: Add hive-specific features to justify abstraction\n- Hybrid: Keep some commands, remove others\n\nThis review should be done after other core features are complete.","status":"closed","priority":4,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T09:25:57.384172919+01:00","created_by":"jsk","updated_at":"2026-02-03T09:39:23.054181212+01:00","closed_at":"2026-02-03T09:39:23.054181212+01:00","close_reason":"## Review Complete: Remove task wrappers\n\n### Findings\n\n| Command | Wraps | Added Value |\n|---------|-------|-------------|\n| `hive task list` | `bd list` | None - pure passthrough |\n| `hive task show` | `bd show` | None - pure passthrough |\n| `hive task add` | `bd create` | Minimal - adds \"discovered work\" note |\n| `hive task too-big` | `bd update --status too_big` | Semantic convenience |\n\n### Evaluation\n\n1. **Value added?** Only `too-big` provides meaningful semantic convenience\n2. **Worth maintenance?** 82 lines code + 229 lines tests for minimal benefit\n3. **Users better off with bd?** Yes - need bd anyway for updates, close, deps\n4. **Hive-specific enhancements?** None implemented (could add worker/worktree info but doesn't)\n5. **Creates confusion?** Yes - two ways to do same thing, docs reference both\n\n### Recommendation: Remove all wrappers\n\n- Users must learn `bd` regardless (only ~10% of bd commands wrapped)\n- Reduces cognitive load (one way to manage tasks)\n- Reduces maintenance burden\n- Update docs to point to `bd` commands directly\n- Keep hive focused on orchestration (`work`, `merge`, `daemon`, `status`)\n\nIf keeping any: only `too-big` is justifiable as workflow convenience."}
{"id":"hive-nf4","title":"Update existing tests for status values","description":"Update mocked status values in:\n- tests/test_work.py\n- tests/test_status.py\nChange 'done' to 'closed' in assertions and mocks","status":"open","priority":3,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:41:57.696822486+01:00","created_by":"jsk","updated_at":"2026-02-03T12:41:57.696822486+01:00","dependencies":[{"issue_id":"hive-nf4","depends_on_id":"hive-7rz","type":"blocks","created_at":"2026-02-03T12:45:07.73955499+01:00","created_by":"jsk"},{"issue_id":"hive-nf4","depends_on_id":"hive-0pp","type":"blocks","created_at":"2026-02-03T12:45:15.308912474+01:00","created_by":"jsk"},{"issue_id":"hive-nf4","depends_on_id":"hive-a13","type":"blocks","created_at":"2026-02-03T12:45:22.847858536+01:00","created_by":"jsk"}]}
{"id":"hive-nu6","title":"Phase 1: Core - Basic planning and serial execution","description":"Core functionality for Hive orchestrator: setup, planning, serial execution, context generation, worktree management, and spawn failure detection.","status":"closed","priority":1,"issue_type":"feature","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:05:31.716459196+01:00","created_by":"jsk","updated_at":"2026-02-03T07:20:42.036199706+01:00","closed_at":"2026-02-03T07:20:42.036199706+01:00","close_reason":"Phase 1 is fully implemented with all tests passing (70/70). Includes: hive init, hive plan, hive work (serial Ralph loop), context generation (CLAUDE.md), worktree management, spawn failure detection, atomic task claiming, dependency tracking, and discovered work support."}
{"id":"hive-ow6","title":"Test discovered task","notes":"Created via hive task add (discovered work)","status":"closed","priority":3,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T14:05:54.867923473+01:00","created_by":"jsk","updated_at":"2026-02-02T14:06:17.790263621+01:00","closed_at":"2026-02-02T14:06:17.790263621+01:00","close_reason":"Test task for discovered-from feature","dependencies":[{"issue_id":"hive-ow6","depends_on_id":"hive-64d","type":"discovered-from","created_at":"2026-02-02T14:05:54.933677311+01:00","created_by":"jsk"}]}
{"id":"hive-qem","title":"Integrate config into work.py","description":"Update work.py to load and use config values instead of hardcoded defaults:\n- spawn_grace_period\n- poll_interval\n- task_timeout\n- agent_command","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:41:23.180602988+01:00","created_by":"jsk","updated_at":"2026-02-03T13:14:47.117334624+01:00","closed_at":"2026-02-03T13:14:47.117334624+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-qem","depends_on_id":"hive-ia1","type":"blocks","created_at":"2026-02-03T12:44:30.468328103+01:00","created_by":"jsk"}]}
{"id":"hive-qgu","title":"Epic: Fix Status Value Mismatch","description":"Fix critical mismatch between Hive expected status values and actual Beads status values. Code checks for 'done' but Beads uses 'closed'. CLAUDE.md template gives wrong instructions to agents.","status":"closed","priority":0,"issue_type":"epic","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:39:27.468229425+01:00","created_by":"jsk","updated_at":"2026-02-03T12:59:34.347810436+01:00","closed_at":"2026-02-03T12:59:34.347810436+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-qgu","depends_on_id":"hive-7rz","type":"blocks","created_at":"2026-02-03T12:47:47.619465861+01:00","created_by":"jsk"},{"issue_id":"hive-qgu","depends_on_id":"hive-0pp","type":"blocks","created_at":"2026-02-03T12:47:54.772973565+01:00","created_by":"jsk"},{"issue_id":"hive-qgu","depends_on_id":"hive-a13","type":"blocks","created_at":"2026-02-03T12:48:02.159121888+01:00","created_by":"jsk"},{"issue_id":"hive-qgu","depends_on_id":"hive-3ep","type":"blocks","created_at":"2026-02-03T12:48:09.828348143+01:00","created_by":"jsk"}]}
{"id":"hive-qko","title":"Phase 4: Polish - Production ready","description":"Production polish: minimal daemon, merge workflow, error handling, recovery, and documentation.","status":"closed","priority":2,"issue_type":"feature","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:05:58.32756924+01:00","created_by":"jsk","updated_at":"2026-02-03T09:35:51.496240012+01:00","closed_at":"2026-02-03T09:35:51.496240012+01:00","close_reason":"All Phase 4 deliverables complete: daemon monitoring, merge workflow, error handling, and documentation. 115 tests pass.","dependencies":[{"issue_id":"hive-qko","depends_on_id":"hive-608","type":"blocks","created_at":"2026-02-02T08:06:33.003390346+01:00","created_by":"jsk"}]}
{"id":"hive-qyo","title":"Implement spawn failure detection","description":"Grace period check (default 30s): if no tmux pane output AND no Beads state change, mark task failed with reason agent_spawn_failed. Prevents tasks stuck in in_progress indefinitely.","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:07:30.449137768+01:00","created_by":"jsk","updated_at":"2026-02-02T09:16:48.891570292+01:00","closed_at":"2026-02-02T09:16:48.891570292+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-qyo","depends_on_id":"hive-djm","type":"blocks","created_at":"2026-02-02T08:10:24.321850021+01:00","created_by":"jsk"}]}
{"id":"hive-rv0","title":"Implement too_big workflow","description":"When agent runs bd update \u003cid\u003e --status too_big, ralph loop detects this, cleans up worktree, and human decomposes via hive plan --continue. Add hive task too-big \u003cid\u003e command.","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:08:08.192889112+01:00","created_by":"jsk","updated_at":"2026-02-02T09:53:08.156005497+01:00","closed_at":"2026-02-02T09:53:08.156005497+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-rv0","depends_on_id":"hive-djm","type":"blocks","created_at":"2026-02-02T08:10:56.337038206+01:00","created_by":"jsk"}]}
{"id":"hive-u5s","title":"Review: Verify hive task removal is complete","description":"Final review after removal. Verify: 1) No 'hive task' references remain in code or docs, 2) All tests pass, 3) hive --help no longer shows task subcommand, 4) Documentation is consistent.","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T09:42:13.201657941+01:00","created_by":"jsk","updated_at":"2026-02-03T12:21:35.060376603+01:00","closed_at":"2026-02-03T12:21:35.060376603+01:00","close_reason":"Review complete - hive task removal verified:\n\n✓ No hive task references in code/docs (only strikethrough checklist items)\n✓ All 102 tests pass (13 task tests removed)\n✓ hive --help does not show task subcommand\n✓ task.py and test_task.py successfully deleted\n✓ Documentation consistent across README.md, hive-plan.md, multi-agent-orchestrator-plan.md\n\nAll hive task wrappers removed. Users now use bd commands directly.","dependencies":[{"issue_id":"hive-u5s","depends_on_id":"hive-4cn","type":"blocks","created_at":"2026-02-03T09:42:57.025450295+01:00","created_by":"jsk"},{"issue_id":"hive-u5s","depends_on_id":"hive-bke","type":"blocks","created_at":"2026-02-03T09:43:04.331139613+01:00","created_by":"jsk"},{"issue_id":"hive-u5s","depends_on_id":"hive-zsm","type":"blocks","created_at":"2026-02-03T09:43:12.10749747+01:00","created_by":"jsk"}]}
{"id":"hive-uxl","title":"Update work.py to use file locking","description":"Refactor worker registry functions in work.py (lines 187-265) to use locked_json_file():\n- register_worker()\n- unregister_worker()\n- update_worker_activity()","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:40:47.529889897+01:00","created_by":"jsk","updated_at":"2026-02-03T13:08:19.964365143+01:00","closed_at":"2026-02-03T13:08:19.964365143+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-uxl","depends_on_id":"hive-9jj","type":"blocks","created_at":"2026-02-03T12:44:15.48141763+01:00","created_by":"jsk"}]}
{"id":"hive-vb6","title":"Update init.py config generation","description":"Update hive init to generate config.toml with new fields:\n- default_branch = 'main'\n- poll_interval = 5\n- task_timeout = 3600","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:41:15.320555882+01:00","created_by":"jsk","updated_at":"2026-02-03T13:13:09.088258196+01:00","closed_at":"2026-02-03T13:13:09.088258196+01:00","close_reason":"Closed"}
{"id":"hive-vsq","title":"Add branch detection to config.py","description":"Add get_default_branch() helper to config.py that:\n1. Checks config for default_branch setting\n2. Falls back to git symbolic-ref refs/remotes/origin/HEAD\n3. Falls back to 'main'","status":"open","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T12:41:35.134394719+01:00","created_by":"jsk","updated_at":"2026-02-03T12:41:35.134394719+01:00","dependencies":[{"issue_id":"hive-vsq","depends_on_id":"hive-ia1","type":"blocks","created_at":"2026-02-03T12:44:37.764984204+01:00","created_by":"jsk"}]}
{"id":"hive-wqs","title":"Write Hive documentation","description":"README with quick start, CLI reference, configuration guide. Document task states, ralph loop, merge policy, parallelization rules. Add examples for common workflows.","status":"closed","priority":3,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:09:32.072082557+01:00","created_by":"jsk","updated_at":"2026-02-03T08:44:08.080606531+01:00","closed_at":"2026-02-03T08:44:08.080606531+01:00","close_reason":"Comprehensive documentation complete. README updated with: quick start guide, complete CLI reference, configuration guide, task states/workflow, Ralph loop explanation, merge policy, parallelization rules, worktree management, common workflows, and troubleshooting guide."}
{"id":"hive-xck","title":"Test discovered task","notes":"Created via hive task add (discovered work)","status":"closed","priority":3,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T09:21:52.989135363+01:00","created_by":"jsk","updated_at":"2026-02-02T09:22:24.71403353+01:00","closed_at":"2026-02-02T09:22:24.71403353+01:00","close_reason":"Test task for hive task add command"}
{"id":"hive-y9v","title":"Implement hive plan command","description":"Interactive planning session: spawn Claude agent, human provides goal/constraints, agent asks clarifying questions, proposes breakdown, human reviews, agent creates Beads tasks with dependencies. Supports --approve and --show flags.","status":"closed","priority":1,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-02T08:06:55.731100613+01:00","created_by":"jsk","updated_at":"2026-02-02T08:41:30.565654385+01:00","closed_at":"2026-02-02T08:41:30.565654385+01:00","close_reason":"Closed","dependencies":[{"issue_id":"hive-y9v","depends_on_id":"hive-krb","type":"blocks","created_at":"2026-02-02T08:09:52.197408562+01:00","created_by":"jsk"}]}
{"id":"hive-zsm","title":"Update other docs and code references to hive task","description":"Search for remaining 'hive task' references in multi-agent-orchestrator-plan.md, plan.py error messages, and any other files. Update to use bd commands.","status":"closed","priority":2,"issue_type":"task","owner":"jsk@norlysenergytrading.com","created_at":"2026-02-03T09:42:05.298561999+01:00","created_by":"jsk","updated_at":"2026-02-03T12:20:01.438317555+01:00","closed_at":"2026-02-03T12:20:01.438317555+01:00","close_reason":"Updated plan.py error message and multi-agent-orchestrator-plan.md. All hive task refs removed from code/docs.","dependencies":[{"issue_id":"hive-zsm","depends_on_id":"hive-dlr","type":"blocks","created_at":"2026-02-03T09:42:49.757411322+01:00","created_by":"jsk"}]}
